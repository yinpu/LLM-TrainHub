# llm-training-tutorial

目标：
- 每个项目相对独立，方便修改，提供示例数据、训练、预测脚本
- 尽可能使用原生transformers的trainer
- 支持ddp、deepspeed
- 在qwen2-1.5b和7b跑通