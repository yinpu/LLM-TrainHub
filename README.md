# LLM Training and Inference Framework

This repository provides a customizable framework for training and inference of large language models (LLM). It is designed for flexibility, ease of modification, and maintaining a consistent style across projects. The core objective is to enable users to easily adapt the code for their own needs, particularly around custom data loading, model architecture adjustments, and custom loss functions, while supporting common LLM training setups.

## Features

- **Modular Projects**: Each project is independent and follows a unified structure for easy navigation and customization.
- **Pre-built Scripts**: Example data, training, and inference scripts are provided for quick setup and usage.
- **Native Transformers Integration**: Wherever possible, the training framework utilizes Hugging Face's `transformers` library, specifically the `Trainer` class, for a seamless experience.
- **Multi-GPU Support**: Distributed Data Parallel (DDP) and DeepSpeed are supported for multi-GPU training.
- **Compatibility**: Verified to work with the Qwen2 series of models.

## Goals

- **Customizable Workflows**: Allow for easy modifications in data loading, model architecture, and loss functions.
- **Efficient Training**: Supports state-of-the-art techniques for LLM training, including LoRA fine-tuning and embedding generation.
- **Flexible Model Handling**: Provides utilities for custom model saving and loading workflows.

## Project Plans

- âœ… **llm-lora-simple**: A simplified single-machine LoRA fine-tuning setup for large language models.
  - ğŸ”„ Migration to DDP, with further adjustments planned.

- âœ… **llm-embedding**: A project to generate embeddings using LLMs.
  - âœ… Fine-tune LLM parameters to generate embeddings.
  - âœ… Freeze LLM parameters and add a fully connected Adapter layer to generate embeddings.

- â³ **LLM Full-Parameter SFT**: Full parameter supervised fine-tuning of large language models.

- â³ **LLM-LoRA Fine-Tuning**: Fine-tuning large language models using LoRA, with plans for scalability improvements.

- â³ **LLM-DPO Training**: Training LLMs using direct preference optimization techniques.

- â³ **Notellm Replication**: Reproducing the Notellm model and its associated tasks.

- â³ **VLM Fine-Tuning**: Fine-tuning vision-language models for specific tasks.


ç›®æ ‡ï¼š
- æ¯ä¸ªé¡¹ç›®ç›¸å¯¹ç‹¬ç«‹ï¼Œæ–¹ä¾¿ä¿®æ”¹ï¼Œæä¾›ç¤ºä¾‹æ•°æ®ã€è®­ç»ƒã€é¢„æµ‹è„šæœ¬
- å°½å¯èƒ½ä½¿ç”¨åŸç”Ÿtransformersçš„trainer
- æ”¯æŒddpã€deepspeed
- åœ¨qwen2-1.5bå’Œ7bè·‘é€š